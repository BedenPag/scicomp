{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euler and Runge-Kutta methods for solving ODEs\n",
    "\n",
    "The Euler method is a first-order numerical method for solving ODEs. It uses a forward difference approximation to estimate the derivative of the solution at each time step and updates the solution accordingly. The basic formula for Euler's method is,\n",
    "\\begin{equation}\n",
    " y_{n+1} = y_n + h \\cdot f(t_n, y_n)\n",
    "\\end{equation}\n",
    "where, $y_n$ is the approximate solution at time $t_n$, $h$ is the time step and $f(t_n, y_n)$ is the derivative of the solution at time $t_n$.\n",
    "\n",
    "Euler method has a first-order global truncation error ($O(h)$), which means that the error in the approximation is proportional to the time step. It is simple to implement but may not be accurate for stiff ODEs which are ODEs with rapidly changing or oscillatory solutions.\n",
    "\n",
    "Runge-Kutta methods are a family of numerical methods for solving ODEs. These methods work by approximating the solution of an ODE at discrete time steps, also known as time discretization. The most commonly used Runge-Kutta method is the fourth-order Runge-Kutta (RK4).\n",
    "\n",
    "The RK4 method uses a weighted average of four derivative evaluations to estimate the derivative of the solution at each time step. The basic formula for RK4 is,\n",
    "\n",
    "\\begin{equation}\n",
    "y_{n+1} = y_n + \\frac{h}{6} \\left( k_1 + 2k_2 + 2k_3 + k_4 \\right),\n",
    "\\end{equation}\n",
    "\n",
    "where $y_n$ is the approximate solution at time $t_n$, $h$ is the time step, and $k_1, k_2, k_3, k_4$ are the weighted derivatives of the solution at time $t_n$. The weighted derivatives are calculated as follows,\n",
    "\n",
    "\\begin{equation}\n",
    "    k_1 = f(t_n, y_n), \\notag \\\\\n",
    "    k_2 = f\\left(t_n + \\frac{h}{2}, y_n + \\frac{h}{2} \\cdot k_1 \\right), \\notag \\\\\n",
    "    k_3 = f\\left(t_n + \\frac{h}{2}, y_n + \\frac{h}{2} \\cdot k_2 \\right), \\notag \\\\\n",
    "    k_4 = f\\left(t_n + h, y_n + h \\cdot k_3 \\right).\n",
    "\\end{equation}\n",
    "\n",
    "RK4 has a fourth-order global truncation error ($O(h^4)$), so it is more accurate than Euler's method. It is also important to note that RK4 is more robust to stiff ODEs than Euler's method.\n",
    "\n",
    "The following code compares the accuracy of Euler method and RK4 for solving the following first-order ODE,\n",
    "\\begin{equation}\n",
    "\\frac{dx}{dt} = -x\n",
    "\\end{equation}\n",
    "\n",
    "where $x(0) = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows that RK4 is more accurate than Euler's method for different time steps. Because it is a fourth-order method, it uses higher-order polynomial approximations to estimate the slope of the solution curve at each time step. On the other hand, RK4 is more computationally expensive than Euler's method because it requires four derivative evaluations at each time step.\n",
    " \n",
    "The following code implements Euler's method and RK4 for solving the following second-order ODE,\n",
    "\\begin{equation}\n",
    "\\frac{d^2 u}{dt^2} = -u\n",
    "\\end{equation}\n",
    "\n",
    "where $u = (x,y)$, $x(0) = 1$ and $y(0) = 1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows that, for a step size of $h = 0.1$, RK4 is very accurate while Euler's method is not. This is because of the aforementioned higher-order polynomial approximations used by RK4. If the step size was reduced, Euler's method would be more accurate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Shooting Method\n",
    "\n",
    "The numerical shooting method is a numerical method for solving boundary value problems (BVPs) for ODEs. BVPs are differential equations within a domain with defined constraints, called boundary conditions. Numerical shooting is particularly useful for solving BVPs where the boundary conditions are unknown or difficult to determine. \n",
    "\n",
    "The basic idea behind numerical shooting is to transform a BVP into an initial value problem (IVP) by \"shooting\" the solution from one boundary towards the other, and then adjusting the initial conditions until the desired boundary conditions are satisfied. This is done by solving the IVP using a numerical ODE solver, such as the Runge-Kutta method, and adjusting the initial conditions until the solution satisfies the boundary conditions.\n",
    "\n",
    "The shooting method can be summarized as follows:\n",
    "\n",
    "1. A guess is made for the unknown initial conditions that would satisfy the boundary conditions. \n",
    "2. The IVP is solved using the guessed initial conditions and, the solution trajectory is obtained from the IVP.\n",
    "3. The initial conditions are adjusted based on the solution trajectory.\n",
    "4. Steps 2 and 3 are repeated until the initial conditions converge to the values that satisfy the boundary conditions.\n",
    "\n",
    "The following code implements the shooting method to solve a specific BVP for the predator-prey model. The model is described by the following system of ODEs:\n",
    "\n",
    "\\begin{equation} \n",
    "    \\frac{dx}{dt} = x \\cdot (1 - x) - \\frac{a \\cdot x \\cdot y}{d + x},\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{dy}{dt} = b \\cdot y \\cdot \\left(1 - \\frac{y}{x}\\right),\n",
    "\\end{equation}\n",
    "\n",
    "where x(t) represents the population of prey, y(t) represents the population of predators, and a, b, and d are parameters.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code can be tested with different initial conditions and parameter values to study the behaviour of the predator-prey model. Such as the stability or the existence of multiple equilibria. The results can be compared with other numerical methods to validate the accuracy of the method. By plotting the phase portrait of the system when $b <  0.26$ we see there is a stable limit cycle because the prey and predator populations oscillate around the equilibrium point. When $b > 0.26$ the system has a stable equilibrium point because the populations converge to the equilibrium point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Continuation Method\n",
    "\n",
    "The numerical continuation method is a method for approximating the solutions to a system of parameterized nonlinear equations. \n",
    "\n",
    "The system is in the form $F(\\textbf{u}, \\lambda) = 0$, where $\\textbf{u}$ is the solution vector and $\\lambda$ is a parameter. The method also requires an initial solution ($\\textbf{u}_0, \\lambda{_0}$). The method works by solving the system of equations for different values of $\\lambda$ and then adjusting the parameter values until the solutions converge to the desired solutions.\n",
    "\n",
    "Continuation methods are advantagious when studying bifurcation behaviors or stability as the parameter changes. Two common algorithms are natural parameter continuation and pseudo-arclength continuation.\n",
    "\n",
    "Natural parameter continuation can be summarized as follows:\n",
    "\n",
    "1. Choose an initial $\\lambda$ value and solve the equations to obtain the corresponding solution.\n",
    "\n",
    "3. Update the $\\lambda$ value by a small step then the system of equations is solved again to obtain the solution at the updated $\\lambda$ value.\n",
    "\n",
    "4. Repeat steps 2 and 3 until the desired range of $\\lambda$ is covered or until convergence is achieved.\n",
    "\n",
    "Psuedo-arclength continuation differs from natural parameter continuation in that it uses the tangent vector of the solution curve as the direction of the parameter update. The step size is computed using the following formula,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Delta s = \\dot{u}_0^* (u - u_0) + \\dot{\\lambda}_0^* (\\lambda - \\lambda_0),\n",
    "\\end{equation}\n",
    "\n",
    "where ($\\dot{u}_0^*, \\dot{\\lambda}_0^*$) is the tangent vector at ($u_0, \\lambda_0$).\n",
    "\n",
    "The algorithm can be summarized as follows:\n",
    "\n",
    "\n",
    "1. Choose an initial $\\lambda$ value and compute the corresponding solution.\n",
    "\n",
    "2. Compute the tangent vector of the solution curve by using the Jacobian matrix of the system of equations.\n",
    "\n",
    "3. Compute the step size $\\Delta s$ using equation (7).\n",
    "\n",
    "4. Predict the solution after the step.\n",
    "\n",
    "5. Using the tangent vector the predicted solution is corrected to obtain the actual solution at the next parameter value.\n",
    "\n",
    "6. Update the value for $\\lambda$ and solve the equations again to obtain the solution at the updated $\\lambda$ value.\n",
    "\n",
    "7. Repeat steps 2, 3, 4, and 5 until the desired parameter range is covered or until convergence is achieved.\n",
    "\n",
    "Psuedo-arclength continuation is more complex and computationally expensive than natural parameter continuation, but it is more robust as it can handle situations where the tangent vector becomes small or vanishes, which can occur at bifurcation points.\n",
    "\n",
    "Natural parameter continuation is more efficient than pseudo-arclength continuation because it does not require the computation of the Jacobian matrix. Though, it is less robust as it fails at turning points.\n",
    "\n",
    "The following code implements natural parameter continuation and pseudo-arclength continuation to solve the following cubic equation,\n",
    "\n",
    "\\begin{equation}\n",
    "    x^3 - x + c = 0,\n",
    "\\end{equation}\n",
    "\n",
    "where $c$ is a parameter that will be varied. \n",
    "\n",
    "..........\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method of Lines\n",
    "\n",
    "The method of lines (MOL) is a numerical method to approximate solutions to partial differential equations (PDEs) on a uniform discrete grid. It works by discretizing the spatial domain using finite differences. This then allows us to write the PDE as an initial value problem (IVP) or a boundary value problem (BVP) in ODEs, which can be solved using a numerical method. The method of lines is a general method that can be used to solve any PDE. However, it is most commonly used to solve PDEs with constant coefficients. The error for MOL is proportional to the step size in the spatial domain, so increasing the number of points in the grid makes the approximation more accurate.\n",
    "\n",
    "There are three types of boundary conditions that can be applied to a BVP; Dirichlet, Neumann, and Robin. A Dirichlet boundary condition is where the boundary value is the solution. A Neumann boundary condition is where the derivative of the solution is the boundary value. A Robin boundary condition is a combination of Dirichlet and Neumann boundary conditions where the boundary value is the derivative of the solution plus a function.\n",
    "\n",
    "To illustrate the use of finite differences with these boundary conditions, we can consider the BVP,\n",
    "\\begin{equation}\n",
    " \\frac{d^2u}{dx^2} + q(x) = 0, u(a) = 0, u(b) = 0.\n",
    "\\end{equation}\n",
    "We will set $q(x) = 1$, $a = 0$, and $b = 1$ for simplicity. By applying Dirichlet boundary conditions and obtaining different solutions we can see how the approximations differ from the exact solution $u_{\\text{exact}} = \\frac{1}{2} \\cdot x \\cdot (1 - x)$. For Neumann and Robin boundary conditions, the approximations are not similar to the exact solution but are similar to one another. This is because the Neumann and Robin boundary conditions impose constraints on the derivative of the solution at the boundary, rather than providing the values of the solution itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each type of boundary condition, the numerical approximation has a significant truncation error when $N = 21$. By setting $N = 101$ the step size is much smaller therefore, the error is much smaller."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit Euler, Implicit Euler, and Crank-Nicolson Methods for PDEs using Method of Lines\n",
    "\n",
    "PDEs can be converted to a system of ODEs using the method of lines and can therefore be solved using numerical methods for ODEs. \n",
    "\n",
    "The explicit Euler method, as mentioned earlier, is a first-order method that approximates the derivative in time using a forward difference. But because a system of ODEs is being solved, the central difference approximation is also used to evaluate the second derivative in space. The basic formula for the explicit Euler method therefore becomes,\n",
    "\n",
    "\\begin{equation}\n",
    "u_{x,t+1} = u_{x,t} + \\frac{D\\Delta t}{(\\Delta x)^2}* \\left( u_{x+1,t} - 2u_{x,t} + u_{x-1,t} \\right),\n",
    "\\end{equation}\n",
    "\n",
    "where $u_{x,t}$ is the approximate solution at time $t$ and space $x$, $\\Delta t$ is the time step, $\\Delta x$ is the space step, and $D$ is the diffusion coefficient.\n",
    "\n",
    "This is the simplest method for solving a system of ODEs but it has some drawbacks. The method is first-order accurate in time and second-order accurate in space making it the least accurate of the three methods.  It is also unstable if,\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{D\\Delta t}{(\\Delta x)^2} > \\frac{1}{2},\n",
    "\\end{equation}\n",
    "\n",
    "which can be restrictive for small values of $\\Delta x$. The explicit Euler method is also unsuitable for solving stiff ODEs because it is a first-order method. \n",
    "\n",
    "The implicit Euler method is a first-order method that approximates the derivative in time using a backward difference instead. This means that the method is unconditionally stable. However, it is computationally more expensive than the explicit Euler method when computing the next time step. The basic formula for the implicit Euler method is,\n",
    "\n",
    "\\begin{equation}\n",
    "u_{x,t+1} = u_{x,t} + \\frac{D\\Delta t}{(\\Delta x)^2}* \\left( u_{x+1,t+1} - 2u_{x,t+1} + u_{x-1,t+1} \\right).\n",
    "\\end{equation}\n",
    "\n",
    "Because, like explicit Eluer, the implicit Euler method is a first-order method, it is not suitable for solving stiff ODEs either. Also like explicit Euler, the implicit Euler method is first-order accurate in time and second-order accurate in space so it is still not very accurate. \n",
    "\n",
    "The Crank-Nicolson method is a second-order method that approximates the derivative in time using a central difference. This means that the method is unconditionally stable and is suitable for solving stiff ODEs. It is also more accurate than the other two methods too because it is second-order accurate in time and space. The basic formula for the Crank-Nicolson method is,\n",
    "\n",
    "\\begin{equation}\n",
    "u_{x,t+1} = u_{x,t} + \\frac{D\\Delta t}{2(\\Delta x)^2}* \\left( u_{x+1,t+1} - 2u_{x,t+1} + u_{x-1,t+1} \\right) + \\\\\n",
    "\\frac{D\\Delta t}{2(\\Delta x)^2}* \\left( u_{x+1,t} - 2u_{x,t} + u_{x-1,t} \\right).\n",
    "\\end{equation}\n",
    "\n",
    "where all variables are the same as in the implicit Euler method. \n",
    "Crank-Nicolson uses a central difference approximation for both the first and second derivatives.\n",
    "\n",
    "To illustrate the use of each method, we can consider the second-order PDE for heat diffusion,\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{du}{dt} = \\kappa \\frac{d^2 u}{dx^2}, 0 < x < L, 0 < t < T,\n",
    "\\end{equation}\n",
    "\n",
    "with zero-temperature boundary conditions, $u=0$ at $x=0,L$, $t>0$, and the initial temperature function, $u_I = \\sin (\\frac{\\pi x}{L})$.\n",
    "\n",
    "The code uses a uniform grid with $N_x$ grid points in the $x$-direction and $N_t$ grid points in the $t$-direction. The step size in the $x$-direction is $h = L/(N_x - 1)$ and the step size in the $t$-direction is $k = T/(N_t - 1)$. The code uses a forward difference approximation for the first derivative and a central difference approximation for the second derivative. The code also uses a forward difference approximation for the time derivative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
